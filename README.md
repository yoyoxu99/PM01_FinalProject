# PM01_FinalProject

ðŸ“Œ Overview
This repository contains the implementation and experimental code for the final course project of Profilierungsmodul Computerlinguistik I â€“ Trustworthy Data-centric AI.
The project focuses on evaluating and analyzing Theory of Mind (ToM) reasoning abilities in Large Language Models (LLMs) using different probing methods.
The main goal of this project is not performance optimization, but to critically examine and improve existing evaluation protocols in the context of trustworthy and data-centric AI.

## ðŸ“‚ Project Structure

```text
PM01_FinalProject/
â”œâ”€â”€ data/                     # Input datasets (JSONL format)
â”‚   â”œâ”€â”€ False_Belief_Task.jsonl
â”‚   â””â”€â”€ Index4_5_Location.jsonl
â”‚
â”œâ”€â”€ results/                  # Model outputs
â”‚   â”œâ”€â”€ mc_*.jsonl
â”‚   â”œâ”€â”€ lm_*.jsonl
â”‚   â””â”€â”€ fr_*.jsonl
â”‚
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ run_*_model.py          # Run model & generate outputs
â”‚   â”œâ”€â”€ eval_*.py             # Evaluation scripts
â”‚   â”œâ”€â”€ lm.py                 # Prompt + Aggregation + Scoring
â”‚   â”œâ”€â”€ mc.py
â”‚   â””â”€â”€ fr.py
â”‚
â”œâ”€â”€ logs/                     # Evaluation logs
â”‚   â””â”€â”€ *.txt
â”‚
â”œâ”€â”€ Figures/                  # Figures in thesis
â”‚
â”œâ”€â”€ summary_final.csv         # Final evaluation results
â”œâ”€â”€ fr_avg.csv                # FR average accuracy
â””â”€â”€ README.md                 # Project documentation

